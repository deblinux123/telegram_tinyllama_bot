# telegram_tinyllama_bot

📄 `README.md` (نسخه فارسی)

```markdown
# 🤖 ربات تلگرام با TinyLLaMA (مدل زبانی محلی و آفلاین)

این پروژه یک ربات تلگرام است که با استفاده از یک مدل زبانی محلی (TinyLLaMA) و بدون نیاز به اینترنت، گزارشی مدیریتی از یک فایل CSV ثابت تولید می‌کند. هدف این پروژه تحلیل داده‌ها و ارائه نمودارها به‌صورت کاملاً آفلاین است.

---

## ✨ ویژگی‌ها

- 🧠 استفاده از مدل زبانی محلی (TinyLLaMA با استفاده از `llama-cpp-python`)
- 📊 تحلیل فایل CSV برای استخراج اطلاعات مدیریتی مانند:
  - توزیع سطح تحصیلات
  - بازه‌های سنی
  - وضعیت تأهل (مجرد یا متأهل)
  - وضعیت شغلی (شاغل یا ترک‌کرده)
  - توزیع جنسیت
- 📈 ارسال نمودارهای تصویری (میله‌ای یا دایره‌ای) در ربات تلگرام
- 🔒 کاملاً آفلاین (بدون استفاده از APIهای خارجی مثل OpenAI)

---

## 🗂 ساختار پروژه

```

telegram\_tinyllama\_bot/
├── bot.py                   # اسکریپت اصلی ربات
├── data/
│   └── df\_final.csv         # فایل داده‌ها
├── models/
│   └── tinyllama.gguf       # فایل مدل محلی (دانلود به صورت دستی)
├── utils/
│   └── data\_analysis.py     # ماژول تحلیل داده‌ها
├── token.txt                # توکن ربات تلگرام (محرمانه نگه دارید)
├── README.md                # مستندات پروژه
└── requirements.txt         # لیست کتابخانه‌های موردنیاز

````

---

## ⚙️ مراحل راه‌اندازی

### ۱. کلون کردن مخزن

```bash
git clone https://github.com/your-username/telegram-tinyllama-bot.git
cd telegram-tinyllama-bot
````

### ۲. نصب پیش‌نیازها

```bash
pip install -r requirements.txt
```

### ۳. آماده‌سازی مدل و داده‌ها

* فایل مدل `.gguf` را در پوشه `models/` قرار دهید
  مثال: `tinyllama-1.1b-chat.Q4_K_M.gguf`
* فایل داده‌ها را به صورت `df_final.csv` در پوشه `data/` قرار دهید

### ۴. تنظیم توکن ربات

توکن دریافتی از [BotFather](https://t.me/BotFather) را در فایل `token.txt` قرار دهید:

```
123456789:AAExampleToken
```

### ۵. اجرای ربات

```bash
python bot.py
```

---

## 📌 اطلاعات مدل

این پروژه از مدل [TinyLLaMA](https://huggingface.co/cognitivecomputations/TinyLlama-1.1B-Chat-v1.0) با فرمت فشرده `GGUF` استفاده می‌کند که توسط [`llama.cpp`](https://github.com/ggerganov/llama.cpp) اجرا می‌شود.

برای دریافت مدل و کامپایل کتابخانه `llama.cpp`، به لینک‌های بالا مراجعه کنید.

---

## 📸 نمونه خروجی‌ها

| فرمان        | پاسخ ربات                                                      |
| ------------ | -------------------------------------------------------------- |
| `/start`     | سلام! لطفاً سوالات مربوط به گزارش مدیریتی را بپرسید.           |
| `/education` | نمودار میله‌ای مربوط به توزیع سطح تحصیلات ارسال می‌شود.        |
| `/status`    | مثلاً: «۶۲٪ از افراد شاغل هستند و ۳۸٪ سازمان را ترک کرده‌اند.» |

---

## ⚠️ توجه

این پروژه صرفاً برای اهداف آموزشی طراحی شده است. اجرای مدل به سخت‌افزار سیستم شما وابسته است.

---

## 📬 مجوز

این پروژه تحت مجوز MIT ارائه شده است. می‌توانید آن را تغییر داده یا توسعه دهید.


